{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initial Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# neighborhood analysis based on Katie's code since scimap seems to be weird\n",
    "import anndata as ad\n",
    "import pandas as pd\n",
    "from scipy import spatial\n",
    "from sklearn.cluster import MiniBatchKMeans\n",
    "from matplotlib import pyplot as plt\n",
    "import plotly.io as pio\n",
    "import plotly.graph_objects as go\n",
    "import scimap as sm\n",
    "import os\n",
    "\n",
    "# running on linux requires the file path to just be the file name, assuming that user has put the file in the same directory as this program\n",
    "\n",
    "anndata_path = \"Multiplex_IHC_studies/Summer_Interns/2024/JT_spatial_analysis/IM_full_data_rmDup.h5ad\" # r\"Z:\\Multiplex_IHC_studies\\Summer_Interns\\2024\\spatial\\JT_TMA_spatial_analysis\\DP20_full_data.h5ad\" # r\"Z:\\Multiplex_IHC_studies\\Summer_Interns\\2024\\spatial\\scimapTest\\TMA27ExNuclei.h5ad\"\n",
    "cmap_path = \"Multiplex_IHC_studies/Eric_Berens/HuBrca_TMA_mIHC/DataAnalysis/ImmMimicry_ColorCodes.xlsx\"\n",
    "\n",
    "adata = ad.read_h5ad(anndata_path)\n",
    "# update adata with the grade fix\n",
    "adata.obs.loc[adata.obs['Subject_ID'] == 'ST-00021143', 'Grade'] = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Functions for Neighborhood Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def relabel(data):\n",
    "    '''\n",
    "    re label immune-mimicked and non immune mimicked neoplastic cells\n",
    "    image: slice of a dataframe for a given image\n",
    "    '''\n",
    "    # print(image)\n",
    "    data['phenotype'] = data['phenotype'].cat.add_categories([\"\", \"PanCK+ NCD\"])\n",
    "    data.loc[(data.phenotype == 'PanCK+') & (data.CC1_func == 0) & (data.GASDERMIN_func == 0) & (data.CC3_func == 0) & (data.CC8_func == 0) & (data.H2AX_func == 0) & (data.CD71_func == 0), 'phenotype'] = 'PanCK+ NCD'\n",
    "    # all remaining PanCK+ cells should be PanCK+ CD since they have at least 1 cell death marker\n",
    "    data.loc[(data.phenotype == 'PanCK+'), 'phenotype'] = 'PanCK+ CD'\n",
    "    return data\n",
    "\n",
    "\n",
    "def create_neighborhoods(tma, seeds, threshold, phenotypes):\n",
    "    '''\n",
    "    Purpose: count the neighbor cell types within the distance threshold, with the seed cell as the center\n",
    "    '''\n",
    "    # remove other cells from analysis\n",
    "    # filtered_tma = tma[tma['phenotype'] != 'Other Immune cells']\n",
    "    filtered_tma = tma\n",
    "   \n",
    "    all_locations = filtered_tma[['X_centroid', 'Y_centroid']].values\n",
    "    kdtree = spatial.KDTree(all_locations)\n",
    "    all_neighbors = []\n",
    "\n",
    "    for i in range(len(all_locations)):\n",
    "\n",
    "        cell_class = filtered_tma['phenotype'].values[i]\n",
    "        neighbor_counts = {}\n",
    "        # if cell_class == seed:\n",
    "        if cell_class in seeds:\n",
    "            # same phenotype as the seed cell\n",
    "            neighbors = kdtree.query_ball_point(all_locations[i], threshold)\n",
    "            neighbors.remove(i)\n",
    "            neighbor_classes = [filtered_tma[\"phenotype\"].values[j] for j in neighbors]\n",
    "            prolif_tumor = 0\n",
    "            non_prolif_tumor = 0\n",
    "            for k in neighbors:\n",
    "                # check if it is a tumor neighbor\n",
    "                if filtered_tma['phenotype'].values[k] == 'nonIMNeoplastic cells':\n",
    "                    # check if it is proliferating\n",
    "                    if filtered_tma['KI67_func'].values[k] == 1:\n",
    "                        prolif_tumor += 1\n",
    "                    else:\n",
    "                        non_prolif_tumor += 1\n",
    "            total_counts = []\n",
    "            for c in phenotypes:\n",
    "                n_count = neighbor_classes.count(c)\n",
    "                neighbor_counts[c] = n_count\n",
    "                total_counts.append(n_count)\n",
    "            count_num = sum(total_counts)\n",
    "            n = 0\n",
    "            for c in phenotypes:\n",
    "                if count_num != 0:\n",
    "                    neighbor_counts[\"percent_\" + c] = total_counts[n] / count_num\n",
    "                else:\n",
    "                    neighbor_counts[\"percent_\" + c] = 0\n",
    "                n += 1\n",
    "            # columns from anndata to add to the neighborhood df and csv file\n",
    "            neighbor_counts['file'] = tma[\"imageid\"].values[0]\n",
    "            neighbor_counts['Subject_ID'] = tma['Subject_ID'].values[i]\n",
    "            neighbor_counts['CellID'] = filtered_tma['CellID'].values[i]\n",
    "            neighbor_counts['index'] = i\n",
    "            neighbor_counts['timepoint'] = tma['timepoint'].values[0]\n",
    "            neighbor_counts['Tx'] = tma['Tx'].values[0]\n",
    "            neighbor_counts['Grade'] = tma['Grade'].values[0]\n",
    "            neighbor_counts['Stage'] = tma['Stage'].values[0]\n",
    "            neighbor_counts['ER'] = tma['ER'].values[0]\n",
    "            neighbor_counts['KI67p_neighbors'] = prolif_tumor\n",
    "            neighbor_counts['KI67n_neighbors'] = non_prolif_tumor\n",
    "            neighbor_counts['seed'] = cell_class\n",
    "\n",
    "            all_neighbors.append(neighbor_counts)\n",
    "\n",
    "    if len(all_neighbors) != 0:\n",
    "        keys = list(all_neighbors[0].keys())  \n",
    "    else:\n",
    "        # print(\"no neighborhood for seed\", seed, tma_region[\"imageid\"].values[0])\n",
    "        keys = []\n",
    "    neigh_df = pd.DataFrame(all_neighbors, columns=keys)\n",
    "    neigh_df.fillna(0)\n",
    "    return neigh_df\n",
    "\n",
    "def remove_control_stains():\n",
    "    # remove controls from the samples we are looking at\n",
    "    filter_controls = adata.obs[adata.obs['Subject_ID'] != 'Tonsil']\n",
    "    filter_controls = filter_controls[filter_controls['Subject_ID'] != \"Spleen\"]\n",
    "    return filter_controls\n",
    "\n",
    "def elbow_method(neigh_df, num_cell_types, clusters, image_path):\n",
    "    # eliminate any neighborhoods that have no neighbor cells\n",
    "    neigh_df['sum'] = neigh_df.iloc[:,:num_cell_types].sum(axis=1)\n",
    "    neigh_df = neigh_df[neigh_df['sum'] != 0]\n",
    "    percent_neigh_df = neigh_df.iloc[:, num_cell_types:num_cell_types+num_cell_types]\n",
    "    percent_data = list(percent_neigh_df[percent_neigh_df.columns].values)\n",
    "    kmeans_error = []\n",
    "\n",
    "    for k in range(1, clusters):\n",
    "        kmeans = MiniBatchKMeans(n_clusters=k, init=\"k-means++\", max_iter=300, n_init=10, random_state=0)\n",
    "        kmeans.fit(percent_data)\n",
    "        kmeans_error.append(kmeans.inertia_)\n",
    "    \n",
    "    plt.plot(range(1, clusters), kmeans_error, 'gs-')\n",
    "    plt.title(\"Elbow Method Graph for Determining # of Clusters\")\n",
    "    plt.xlabel(\"# of clusters\")\n",
    "    plt.ylabel(\"WCSS\")\n",
    "    plt.savefig(image_path)\n",
    "    plt.close()\n",
    "\n",
    "def cluster_neighborhoods(neigh_df, num_cell_types, add_cols, k, csv_path):\n",
    "    # cluster based on neighborhoods created in create_neighborhoods()\n",
    "    neigh_df['sum'] = neigh_df.iloc[:,:num_cell_types].sum(axis=1)\n",
    "    neigh_df = neigh_df[neigh_df['sum'] != 0]\n",
    "    percent_neigh_df = neigh_df.iloc[:, num_cell_types:num_cell_types+num_cell_types]\n",
    "    percent_data = list(percent_neigh_df[percent_neigh_df.columns].values)\n",
    "\n",
    "    kmeans = MiniBatchKMeans(n_clusters=k, init='k-means++', max_iter=300, n_init=10, random_state=0) # not sure if these parameters should be changed here\n",
    "    predictions = kmeans.fit_predict(percent_data)\n",
    "\n",
    "    percent_neigh_df['cluster'] = predictions\n",
    "    percent_neigh_df['file'] = neigh_df['file']\n",
    "    percent_neigh_df['CellID'] = neigh_df['CellID']\n",
    "    percent_neigh_df['index'] = neigh_df['index']\n",
    "    # percent_neigh_df['KI67_ratio'] = neigh_df['KI67_ratio']\n",
    "    percent_neigh_df['seed'] = neigh_df['seed']\n",
    "    # percent_neigh_df['Subtype'] = neigh_df['Subtype']\n",
    "    for add_col in add_cols:\n",
    "        percent_neigh_df[add_col] = neigh_df[add_col]\n",
    "    percent_neigh_df.to_csv(csv_path, index=False)\n",
    "    neigh_df['cluster'] = predictions\n",
    "    return percent_neigh_df, neigh_df\n",
    "\n",
    "def read_color_map(path):\n",
    "    cmap_df = pd.read_excel(path)\n",
    "    cmap_df.pop(\"Color\")\n",
    "    cmap_dict = pd.Series(cmap_df.Hex.values, index=cmap_df.Population).to_dict()\n",
    "    return cmap_dict\n",
    "\n",
    "def stacked_bar_plot(df, x_axis, image_name, x_axis_title, y_axis_title, cmap, title):\n",
    "    traces = []\n",
    "    layout = {'xaxis':{'title':x_axis_title}, 'yaxis':{'title':y_axis_title}, 'barmode':'stack', 'height': 800, 'title':title}\n",
    "    for i in range(len(df)):\n",
    "        # get cell class name\n",
    "        cell_class = df.index[i].split(\"_\")[-1]\n",
    "        # if cell_class == \"CD\" or cell_class == \"NCD\":\n",
    "        #     cell_class = \"PanCK+\" + \"_\" + cell_class\n",
    "        trace = {'type':'bar', 'x': x_axis, 'y': list(df.iloc[i, 0:]), 'name': cell_class, 'marker':{'color':cmap[cell_class]}}\n",
    "        traces.append(trace)\n",
    "    fig = {'data': traces, 'layout': layout}\n",
    "    pio.show(fig, renderer='notebook')\n",
    "    pio.write_image(fig, image_name)\n",
    "\n",
    "def plot_cluster(cluster_df, num_cell_types, image_name, k, cmap, title):\n",
    "    '''\n",
    "    to plot the composition of the clustered cellular neighborhoods\n",
    "    '''\n",
    "    cluster_df.drop(['file'], axis=1)\n",
    "    cluster_df.drop(['index'], axis=1)\n",
    "    cluster_df.drop(['CellID'], axis=1)\n",
    "    cluster_df_filtered = cluster_df.iloc[:,:num_cell_types]\n",
    "\n",
    "    cluster_df_filtered['cluster'] = cluster_df['cluster'].values\n",
    "    cluster_df_filtered = cluster_df_filtered.groupby(['cluster']).mean()\n",
    "\n",
    "    cluster_df_filtered = cluster_df_filtered.T\n",
    "    col_dict = {}\n",
    "    for j in range(k):\n",
    "        col_dict[j] = str(j+1)\n",
    "    cluster_df_filtered = cluster_df_filtered.rename(columns=col_dict)\n",
    "    # print(cluster_df_filtered)\n",
    "    stacked_bar_plot(cluster_df_filtered, list(cluster_df_filtered.columns), image_name, \"Cluster\", \"Fraction Present\", cmap, title)\n",
    "\n",
    "# find out if clusters are distrbuted across TMAs\n",
    "# look for whether there is bias where 1 neighborhood cluster comes from just 1/a few TMAs, or distributed\n",
    "\n",
    "def get_cluster_vals(cluster_df, k):\n",
    "    images = cluster_df['file']\n",
    "    cluster_vals = [[] for _ in range(k)]\n",
    "    for i in range(len(images)):\n",
    "        for j in range(k):\n",
    "            if cluster_df.iloc[i]['cluster'] == j:\n",
    "                cluster_vals[j].append(1) # count\n",
    "            else:\n",
    "                cluster_vals[j].append(0)\n",
    "    return cluster_vals\n",
    "\n",
    "def get_sort_indices(indices, order):\n",
    "    lst = []\n",
    "    order_idx = 0\n",
    "    while order_idx < len(order):\n",
    "        for i in indices:\n",
    "            if order[order_idx] in i:\n",
    "                # for NT_ST make sure not to take LMNT_ST\n",
    "                if order[order_idx] == \"NT_ST\":\n",
    "                    if \"LMNT_ST\" not in i:\n",
    "                        lst.append(i)\n",
    "                # for LumB make sure not to take LumBH\n",
    "                elif order[order_idx] == \"LumB\":\n",
    "                    if \"LumBH\" not in i:\n",
    "                        lst.append(i)\n",
    "                else:\n",
    "                    lst.append(i)\n",
    "        order_idx += 1\n",
    "    return lst\n",
    "\n",
    "def cluster_dist_stacked_bar_plot(cluster_df, x_axis_val, k, image_name, image_width=None, image_height=None, sort_by=None, percent=False, groupby=None):\n",
    "    cluster_vals = get_cluster_vals(cluster_df, k)\n",
    "    data_dict = {}\n",
    "    if groupby != None:\n",
    "        data_dict[groupby] = cluster_df[groupby]\n",
    "    else:\n",
    "        data_dict[x_axis_val] = cluster_df[x_axis_val]\n",
    "    for cluster in range(k):\n",
    "        data_dict['cluster ' + str(cluster + 1)] = cluster_vals[cluster]\n",
    "    \n",
    "    cluster_images = pd.DataFrame(data=data_dict)\n",
    "    if groupby == None:\n",
    "        cluster_df_filtered = cluster_images.groupby([x_axis_val]).sum()\n",
    "    else:\n",
    "        cluster_df_filtered = cluster_images.groupby([groupby]).sum()\n",
    "        files = list(cluster_df['file'].unique())\n",
    "        subtypes = []\n",
    "        for i in range(len(cluster_df)):\n",
    "            if cluster_df.iloc[i]['file'] in files:\n",
    "                # add this image's subtype to the list\n",
    "                roi = cluster_df.iloc[i]['file'].split(\"_\")[-1]\n",
    "                subtypes.append(cluster_df.iloc[i]['Subtype'] + \"_\" + roi)\n",
    "                files.remove(cluster_df.iloc[i]['file'])\n",
    "        cluster_df_filtered['Subtype'] = subtypes\n",
    "        cluster_df_filtered = cluster_df_filtered.set_index('Subtype')\n",
    "\n",
    "    if percent == True:\n",
    "        # want the y axis to show percentage rather than just count\n",
    "        row_sums = cluster_df_filtered.sum(axis=1)\n",
    "        for i in range(len(cluster_df_filtered)):\n",
    "            cluster_df_filtered.iloc[i] = cluster_df_filtered.iloc[i].div(row_sums.iloc[i])\n",
    "\n",
    "    if sort_by != None:\n",
    "        if sort_by == \"Subtype\":\n",
    "            indices = cluster_df_filtered.index\n",
    "            order = [\"NB\", \"ILC\", \"LumA\", \"LumB\", \"LumBH\", \"Her2\", \"TN\"]\n",
    "            sorted_indices = get_sort_indices(indices, order)\n",
    "            cluster_df_filtered = cluster_df_filtered.reindex(sorted_indices)\n",
    "        elif sort_by == \"Tx_Timepoint\":\n",
    "            indices = cluster_df_filtered.index\n",
    "            # NT - LMNT - PTX - Ent - 2x - 3xNR - 3xR - 4x - 4xAST 3xNR - 3xR - 4x - bpost - bpre\n",
    "            order = [\"NT_ST\", \"LMNT_ST\", \"PTX_ST\", \"Ent_ST\", \"2x_ST\", \"3xNR_ST\", \"3xR_ST\", \"4x_ST\", \"4xAST_ST\", \"3xNR_LT\", \"3xR_LT\", \"4x_LT\", \"Bpost_LT\", \"Bpre_LT\"]\n",
    "            sorted_indices = get_sort_indices(indices, order)\n",
    "            cluster_df_filtered = cluster_df_filtered.reindex(sorted_indices)\n",
    "        else:   \n",
    "            cluster_df_filtered = cluster_df_filtered.sort_values(by=[sort_by], ascending=False)\n",
    "\n",
    "\n",
    "    cluster_df_filtered = cluster_df_filtered.T\n",
    "    # print(cluster_df_filtered)\n",
    "    # before transpose format of df\n",
    "    #           cluster 1  2  3  4  5\n",
    "    # image x\n",
    "    # image y\n",
    "    # image z\n",
    "    x_axis = list(cluster_df_filtered.columns)\n",
    "\n",
    "    data = [] # make list of go.Bars for the graph\n",
    "    for i in range(len(cluster_df_filtered)):\n",
    "        bar = go.Bar(name='cluster ' + str(i + 1), x=x_axis, y=cluster_df_filtered.iloc[i, 0:])\n",
    "        data.append(bar)\n",
    "    if percent == False:\n",
    "        y_axis_title = \"count\"\n",
    "    else:\n",
    "        y_axis_title = \"percent\"\n",
    "    x_axis_title = x_axis_val\n",
    "    layout = {'xaxis':{'title':x_axis_title}, 'yaxis':{'title':y_axis_title}}\n",
    "    fig = go.Figure(data=data, layout=layout)\n",
    "    fig.update_layout(barmode='stack')\n",
    "    fig.show(renderer='notebook')\n",
    "    fig.write_image(image_name, width=image_width, height=image_height)\n",
    "\n",
    "def investigate_cluster_distribution(cluster_df, k):\n",
    "    '''\n",
    "    plots cluster distributions as desired\n",
    "    '''\n",
    "\n",
    "    # stacked bars for each ROI, group by subtype\n",
    "    # do x axis as image id, then instead of cell type, stack by cluster classification\n",
    "    # cluster_dist_stacked_bar_plot(cluster_df, \"file\", k, \"Multiplex_IHC_studies/Summer_Interns/2024/JT_spatial_output/IM_graphs/IM2/IM_cluster_distribution.png\", 2000)\n",
    "\n",
    "    # # plot all clusters but sorted by lowest to highest cluster 2, with y axis as percentage of each cluster\n",
    "    cluster_dist_stacked_bar_plot(cluster_df=cluster_df, x_axis_val=\"Subject_ID\", k=k, image_name=\"Multiplex_IHC_studies/Summer_Interns/2024/JT_spatial_output/IM_graphs/FINAL_IM/sorted_cluster_distribution.png\", image_width=1000, sort_by=\"cluster 4\", percent=True)\n",
    "    # # x axis as subtype, and then cluster as y\n",
    "    # grade3 = cluster_df.loc[cluster_df['Grade'] == 3]\n",
    "    # cluster_dist_stacked_bar_plot(cluster_df=cluster_df, x_axis_val=\"timepoint\", k=k, image_name=\"Multiplex_IHC_studies/Summer_Interns/2024/JT_spatial_output/IM_graphs/IM2/IM_grouped_tx_cluster_distribution.png\", image_height=600)\n",
    "    # # ER status\n",
    "    # cluster_dist_stacked_bar_plot(cluster_df=cluster_df, x_axis_val=\"ER\", k=k, image_name=\"Multiplex_IHC_studies/Summer_Interns/2024/JT_spatial_output/IM_graphs/IM2/IM_grouped_er_cluster_distribution.png\", image_height=600, percent=True)\n",
    "    # cluster_dist_stacked_bar_plot(cluster_df=cluster_df, x_axis_val=\"Subject_ID\", k=k, image_name=\"Multiplex_IHC_studies/Summer_Interns/2024/JT_spatial_output/IM_graphs/IM2/IM_subject_cluster_distribution.png\", image_width=2000)\n",
    "\n",
    "    # cluster_dist_stacked_bar_plot(cluster_df=cluster_df, x_axis_val=\"Grade\", k=k, image_name=\"Multiplex_IHC_studies/Summer_Interns/2024/JT_spatial_output/IM_graphs/IM2/IM_grade_cluster_distribution.png\", image_height=600)\n",
    "\n",
    "    # cluster_dist_stacked_bar_plot(cluster_df=cluster_df, x_axis_val=\"Tx_Timepoint\", k=k, image_name=\"Multiplex_IHC_studies/Summer_Interns/2024/JT_spatial_output/DP20_graphs/DP_sorted_tx_cluster_distribution.png\", image_width=1000, image_height=600, sort_by=\"Tx_Timepoint\", percent=False)\n",
    "\n",
    "def find_cell_cluster(source_row, cluster_df):\n",
    "    # gets cluster for seed cells\n",
    "    name = source_row.name\n",
    "    name_parts = name.split(\"_\")\n",
    "    file = name_parts[0] + \"_\" + name_parts[1]\n",
    "    cellid = name_parts[-1]\n",
    "    source_location = cluster_df[cluster_df[\"file\"] == file]\n",
    "    found_row = source_location[source_location['CellID'] == int(cellid)]\n",
    "    try:\n",
    "        cluster = int(found_row['cluster'])\n",
    "    except TypeError:\n",
    "        cluster = None\n",
    "    return cluster\n",
    "\n",
    "def spatial_scatterPlot (adata, \n",
    "                         colorBy, \n",
    "                         topLayer=None,\n",
    "                         x_coordinate='X_centroid',\n",
    "                         y_coordinate='Y_centroid',\n",
    "                         imageid='imageid',\n",
    "                         layer=None,\n",
    "                         subset=None,\n",
    "                         s=None,\n",
    "                         ncols=None,\n",
    "                         alpha=1,\n",
    "                         dpi=200,\n",
    "                         fontsize=None,\n",
    "                         plotLegend=True,\n",
    "                         cmap='RdBu_r',\n",
    "                         catCmap='tab20',\n",
    "                         vmin=None,\n",
    "                         vmax=None,\n",
    "                         customColors=None,\n",
    "                         figsize=(5, 5),\n",
    "                         invert_yaxis=True,\n",
    "                         saveDir=None,\n",
    "                         fileName='scimapScatterPlot.png',\n",
    "                         title=None,\n",
    "                         **kwargs):\n",
    "\n",
    "    import anndata as ad\n",
    "    import pathlib\n",
    "    import matplotlib.pyplot as plt\n",
    "    import pandas as pd\n",
    "    import math\n",
    "    import numpy as np\n",
    "    import matplotlib.patches as mpatches\n",
    "    import matplotlib as mpl\n",
    "    import os\n",
    "    # Load the andata object\n",
    "    if isinstance(adata, str):\n",
    "        adata = ad.read(adata)\n",
    "    else:\n",
    "        adata = adata.copy()\n",
    "\n",
    "    # subset data if neede\n",
    "    if subset is not None:\n",
    "        if isinstance (subset, str):\n",
    "            subset = [subset]\n",
    "        if layer == 'raw':\n",
    "            bdata=adata.copy()\n",
    "            bdata.X = adata.raw.X\n",
    "            bdata = bdata[bdata.obs[imageid].isin(subset)]\n",
    "        else:\n",
    "            bdata=adata.copy()\n",
    "            bdata = bdata[bdata.obs[imageid].isin(subset)]\n",
    "    else:\n",
    "        bdata=adata.copy()\n",
    "\n",
    "    # isolate the data\n",
    "    if layer is None:\n",
    "        data = pd.DataFrame(bdata.X, index=bdata.obs.index, columns=bdata.var.index)\n",
    "    elif layer == 'raw':\n",
    "        data = pd.DataFrame(bdata.raw.X, index=bdata.obs.index, columns=bdata.var.index)\n",
    "    else:\n",
    "        data = pd.DataFrame(bdata.layers[layer], index=bdata.obs.index, columns=bdata.var.index)\n",
    "\n",
    "    # isolate the meta data\n",
    "    meta = bdata.obs\n",
    "\n",
    "    # toplayer logic\n",
    "    if isinstance (topLayer, str):\n",
    "        topLayer = [topLayer]  \n",
    "\n",
    "    # identify the things to color\n",
    "    if isinstance (colorBy, str):\n",
    "        colorBy = [colorBy]   \n",
    "    # extract columns from data and meta\n",
    "    data_cols = [col for col in data.columns if col in colorBy]\n",
    "    meta_cols = [col for col in meta.columns if col in colorBy]\n",
    "    # combine extracted columns from data and meta\n",
    "    colorColumns = pd.concat([data[data_cols], meta[meta_cols]], axis=1)\n",
    "\n",
    "    # identify the x and y coordinates\n",
    "    x = meta[x_coordinate]\n",
    "    y = meta[y_coordinate]\n",
    "\n",
    "\n",
    "    # auto identify rows and columns in the grid plot\n",
    "    def calculate_grid_dimensions(num_items, num_columns=None):\n",
    "        \"\"\"\n",
    "        Calculates the number of rows and columns for a square grid\n",
    "        based on the number of items.\n",
    "        \"\"\"\n",
    "        if num_columns is None:\n",
    "            num_rows_columns = int(math.ceil(math.sqrt(num_items)))\n",
    "            return num_rows_columns, num_rows_columns\n",
    "        else:\n",
    "            num_rows = int(math.ceil(num_items / num_columns))\n",
    "            return num_rows, num_columns\n",
    "\n",
    "    # calculate the number of rows and columns\n",
    "    nrows, ncols = calculate_grid_dimensions(len(colorColumns.columns), num_columns = ncols)\n",
    "\n",
    "\n",
    "    # resolve figsize\n",
    "    #figsize = (figsize[0]*ncols, figsize[1]*nrows)\n",
    "\n",
    "    # Estimate point size\n",
    "    if s is None:\n",
    "        s = (10000 / bdata.shape[0]) / len(colorColumns.columns)\n",
    "\n",
    "    # Define the categorical colormap (optional)\n",
    "    cmap_cat = plt.get_cmap(catCmap)\n",
    "\n",
    "    # FIIGURE\n",
    "    fig, axs = plt.subplots(nrows=nrows, ncols=ncols, figsize=figsize, dpi=dpi)\n",
    "\n",
    "    # Flatten the axs array for easier indexing\n",
    "    if nrows == 1 and ncols == 1:\n",
    "        axs = [axs]  # wrap single subplot in a list\n",
    "    else:\n",
    "        axs = axs.flatten()\n",
    "\n",
    "    # Loop over the columns of the DataFrame\n",
    "    for i, col in enumerate(colorColumns):\n",
    "        # Select the current axis\n",
    "        ax = axs[i]\n",
    "\n",
    "        # invert y-axis\n",
    "        if invert_yaxis is True:\n",
    "            ax.invert_yaxis()\n",
    "\n",
    "        # Scatter plot for continuous data\n",
    "        # print(colorColumns[col])\n",
    "        if colorColumns[col].dtype.kind in 'iufc':\n",
    "            # print(\"continuous\")\n",
    "            scatter = ax.scatter(x=x, y=y, \n",
    "                                 c=colorColumns[col], \n",
    "                                 cmap=cmap, \n",
    "                                 s=s,\n",
    "                                 vmin=vmin,\n",
    "                                 vmax=vmax,\n",
    "                                 linewidths=0,\n",
    "                                 alpha=alpha, **kwargs)\n",
    "            if plotLegend is True:\n",
    "                cbar = plt.colorbar(scatter, ax=ax, pad=0)\n",
    "                cbar.ax.tick_params(labelsize=fontsize)\n",
    "\n",
    "        # Scatter plot for categorical data\n",
    "        else:\n",
    "            # Get the unique categories in the column\n",
    "            categories = colorColumns[col].unique()\n",
    "            # print(\"Categorical\", categories)\n",
    "\n",
    "            # Map the categories to colors using either the custom colors or the categorical colormap\n",
    "            if customColors:\n",
    "                colors = {cat: customColors[cat] for cat in categories if cat in customColors}\n",
    "            else:\n",
    "                colors = {cat: cmap_cat(i) for i, cat in enumerate(categories)}\n",
    "\n",
    "            # Ensure topLayer categories are plotted last\n",
    "            categories_to_plot_last = [cat for cat in topLayer if cat in categories] if topLayer else []\n",
    "            categories_to_plot_first = [cat for cat in categories if cat not in categories_to_plot_last]\n",
    "\n",
    "            # Plot non-topLayer categories first\n",
    "            for cat in categories_to_plot_first:\n",
    "                cat_mask = colorColumns[col] == cat\n",
    "                ax.scatter(x=x[cat_mask], y=y[cat_mask], \n",
    "                           c=[colors.get(cat, cmap_cat(np.where(categories == cat)[0][0]))],\n",
    "                           s=s, linewidths=0, alpha=alpha, **kwargs)\n",
    "\n",
    "            # Then plot topLayer categories\n",
    "            for cat in categories_to_plot_last:\n",
    "                cat_mask = colorColumns[col] == cat\n",
    "                ax.scatter(x=x[cat_mask], y=y[cat_mask], \n",
    "                           c=[colors.get(cat, cmap_cat(np.where(categories == cat)[0][0]))],\n",
    "                           s=s, linewidths=0, alpha=alpha, **kwargs)\n",
    "\n",
    "            if plotLegend is True:\n",
    "                # Adjust legend to include all categories\n",
    "                sorted_categories = sorted(categories)\n",
    "                handles = [mpatches.Patch(color=colors.get(cat, cmap_cat(np.where(categories == cat)[0][0])), label=cat) for cat in sorted_categories]\n",
    "                ax.legend(handles=handles, bbox_to_anchor=(1.0, 1.0), loc='upper left', bbox_transform=ax.transAxes, fontsize=fontsize)\n",
    "\n",
    "        if title == None:\n",
    "            title = col\n",
    "        ax.set_title(title)  # fontsize=fontsize\n",
    "        ax.set_yticklabels([])\n",
    "        ax.set_xticklabels([])\n",
    "        ax.set_xticks([])\n",
    "        ax.set_yticks([])\n",
    "\n",
    "\n",
    "    # Remove any empty subplots\n",
    "    num_plots = len(colorColumns.columns)\n",
    "    for i in range(num_plots, nrows * ncols):\n",
    "        ax = axs[i]\n",
    "        fig.delaxes(ax)\n",
    "\n",
    "    # Adjust the layout of the subplots grid\n",
    "    plt.tick_params(axis='both', labelsize=fontsize)\n",
    "    plt.tight_layout()\n",
    "\n",
    "    # save figure    \n",
    "    if saveDir:\n",
    "        if not os.path.exists(saveDir):\n",
    "            os.makedirs(saveDir)\n",
    "        full_path = os.path.join(saveDir, fileName)\n",
    "        plt.savefig(full_path, dpi=dpi)\n",
    "        # plt.show()\n",
    "        plt.close()\n",
    "        print(f\"Saved plot to {full_path}\")\n",
    "    else:\n",
    "        plt.show()\n",
    "\n",
    "def prolif_tumor_ratio(cluster_4):\n",
    "    # profileration ratio for tumor cells near and not near immune-mimicked cells\n",
    "\n",
    "    slice = cluster_4.loc[(cluster_4['percent_KI67- IMNeoplastic cells CD69hi'] > 0) | (cluster_4['percent_KI67+ IMNeoplastic cells CD69hi'] > 0) | (cluster_4['seed'] == 'KI67- IMNeoplastic cells CD69hi') | (cluster_4['seed'] == 'KI67+ IMNeoplastic cells CD69hi')]\n",
    "    tumor_slice = cluster_4.loc[(cluster_4['percent_KI67- IMNeoplastic cells CD69hi'] == 0) & (cluster_4['percent_KI67+ IMNeoplastic cells CD69hi'] == 0) & (cluster_4['seed'] != 'KI67- IMNeoplastic cells CD69hi') & (cluster_4['seed'] != 'KI67+ IMNeoplastic cells CD69hi')]\n",
    "\n",
    "    cluster_ratio = slice[['cluster', 'KI67_ratio']]\n",
    "    # cluster_ratio.set_index('cluster', inplace=True)\n",
    "    # cluster_ratio = cluster_ratio.groupby('cluster').mean()\n",
    "    cluster_ratio['cluster'] = cluster_ratio['cluster'].map({0:1, 1:2, 2:3, 3:4})\n",
    "    fig = go.Figure()\n",
    "    # ['Tumor cells near Immune-mimicked', 'Tumor cells not near Immune-mimicked']\n",
    "    fig.add_trace(\n",
    "        go.Box(y=slice['KI67_ratio'],\n",
    "        name='Near Immune-mimicked',\n",
    "        # boxpoints='all',\n",
    "        boxmean=True)\n",
    "    )\n",
    "    fig.add_trace(\n",
    "        go.Box(y=tumor_slice['KI67_ratio'],\n",
    "        name='Not near Immune-mimicked',\n",
    "        # boxpoints='all',\n",
    "        boxmean=True)\n",
    "    )\n",
    "    fig.update_layout(showlegend=False, title=\"Proliferating Tumor Ratio for Tumor Cells Near to and Far from Immune-Mimicked Cells\", width=700, xaxis_title=\"Tumor Neighbor Location\", yaxis_title=\"KI67 ratio\")\n",
    "    fig.show(renderer='notebook')\n",
    "    \n",
    "    # to generate cluster KI67 ratio\n",
    "    # df = pd.read_csv(\"Multiplex_IHC_studies/Summer_Interns/2024/JT_spatial_output/spreadsheets/IM2/IM_create_all_neighborhoods_ki67.csv\")\n",
    "    # df['KI67_ratio'] = df['KI67p_neighbors'] / (df['KI67p_neighbors'] + df['KI67n_neighbors'])\n",
    "    # # cluster_ratio = df[['cluster', 'KI67_ratio']]\n",
    "    # # cluster_ratio\n",
    "\n",
    "    # cluster_ratio\n",
    "    # box plots\n",
    "    # import plotly.express as px\n",
    "    # box_fig = px.box(cluster_ratio, x='cluster', y='KI67_ratio', points=False, title=\"KI67+ Neoplastic / Neoplastic Ratios for Clusters\")\n",
    "    # box_fig.write_image(\"Multiplex_IHC_studies/Summer_Interns/2024/JT_spatial_output/IM_graphs/IM2/IM_ki67_ratio_box_no_outliers.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Main Script for Analysis, can be changed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate neighborhoods\n",
    "filtered_adata = remove_control_stains() \n",
    "tma_images = list(filtered_adata[\"imageid\"].unique())\n",
    "phenotypes = list(filtered_adata['phenotype'].unique())\n",
    "\n",
    "# should seed all tumor cells \n",
    "# KI67+ IMNeoplastic cells CD69hi, KI67- IMNeoplastic cells, nonIMNeoplastic cells\n",
    "seeds = [\"KI67+ IMNeoplastic cells CD69hi\", \"KI67- IMNeoplastic cells CD69hi\", \"nonIMNeoplastic cells\"]\n",
    "first_df = True\n",
    "df = None\n",
    "neighborhood_radius = 120\n",
    "\n",
    "for tma in tma_images:\n",
    "    tma_region = filtered_adata[filtered_adata[\"imageid\"] == tma]\n",
    "    # have every cell type be treated as seed so each will get assigned a cluster later on\n",
    "    # for seed in seeds:\n",
    "    if first_df == True:\n",
    "        df = create_neighborhoods(tma_region, seeds, neighborhood_radius, phenotypes)\n",
    "        first_df = False\n",
    "    else:\n",
    "        df = pd.concat([df, create_neighborhoods(tma_region, seeds, neighborhood_radius, phenotypes)])\n",
    "    print(\"Calculated neighborhood for\", tma)\n",
    "\n",
    "# changed path for running on linux\n",
    "neighborhood_path = \"Multiplex_IHC_studies/Summer_Interns/2024/JT_spatial_output/spreadsheets/IM2/IM_create_all_neighborhoods_SUBJ.csv\"\n",
    "df.to_csv(neighborhood_path, index=False)\n",
    "# save neighbor counts to adata.uns\n",
    "adata.uns['custom_neighborhoods'] = df\n",
    "\n",
    "# generate elbow plot\n",
    "types = len(adata.obs['phenotype'].unique())\n",
    "clusters = 15\n",
    "image_path = \"Multiplex_IHC_studies/Summer_Interns/2024/JT_spatial_output/IM_graphs/FINAL_IM/Elbow_Plot.png\"\n",
    "elbow_method(df, types, clusters, image_path)\n",
    "\n",
    "# determine number of clusters based on elbow plot and generate cluster csv\n",
    "add_cols = ['timepoint', 'Tx', 'Grade', 'Stage', 'ER', 'Subject_ID']\n",
    "k = 4\n",
    "csv_path = \"Multiplex_IHC_studies/Summer_Interns/2024/JT_spatial_output/spreadsheets/IM2/IM_neighborhood_cluster4.csv\"\n",
    "cluster_4, neigh_cluster_4 = cluster_neighborhoods(df, types, add_cols, k, csv_path)\n",
    "\n",
    "# generate image of cluster cell type composition\n",
    "cmap_path = \"Multiplex_IHC_studies/Eric_Berens/HuBrca_TMA_mIHC/DataAnalysis/ImmMimicry_ColorCodes.xlsx\"\n",
    "cmap = read_color_map(cmap_path)\n",
    "image_name = \"Multiplex_IHC_studies/Summer_Interns/2024/JT_spatial_output/IM_graphs/FINAL_IM/IM_cluster_composition4.png\"\n",
    "plot_cluster(cluster_4, types, image_name, k, cmap, \"Neighborhood Cluster Cell Type Composition\")\n",
    "\n",
    "# generate cluster graphs, edit this function to change what you want to see\n",
    "investigate_cluster_distribution(cluster_4, k)\n",
    "\n",
    "# plot clusters in a particular order\n",
    "high = ['ST-00011028', 'ST-00006692', 'ST-00018308', 'ST-00021050', 'ST-00006399', 'ST-00018307', 'ST-00021143', 'ST-00018343', 'ST-00016958']\n",
    "mid = ['ST-00006415', 'ST-00014645', 'ST-00018134 - RT', 'ST-00015949', 'ST-00018134 - LT','ST-00006630', 'ST-00017876','ST-00019469', 'ST-00017405']\n",
    "low = [ 'ST-00014447', 'ST-00013076', 'ST-00006152', 'ST-00017865', 'ST-00022280',   'ST-00006624', 'ST-00006509', 'ST-00023046']\n",
    "subj_order = high + mid + low\n",
    "# by grade and ER status\n",
    "# cluster_dist_stacked_bar_plot(cluster_df=cluster_4, x_axis_val=\"Subject_ID\", k=k, image_name=\"Multiplex_IHC_studies/Summer_Interns/2024/JT_spatial_output/IM_graphs/FINAL_IM/count_cluster_distribution.png\", image_width=1000)\n",
    "cluster_dist_stacked_bar_plot(cluster_df=cluster_4, x_axis_val=\"Grade\", k=k, image_name=\"Multiplex_IHC_studies/Summer_Interns/2024/JT_spatial_output/IM_graphs/FINAL_IM/grade_cluster_distribution.png\", image_height=600, percent=True)\n",
    "cluster_dist_stacked_bar_plot(cluster_df=cluster_4, x_axis_val=\"ER\", k=k, image_name=\"Multiplex_IHC_studies/Summer_Interns/2024/JT_spatial_output/IM_graphs/FINAL_IM/er_cluster_distribution.png\", image_height=600, percent=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualization of Clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize clusters\n",
    "clusters = []\n",
    "count = 0\n",
    "for i in range(len(adata.obs)):\n",
    "    if adata.obs.iloc[i]['phenotype'] == \"Other Cells\" or adata.obs.iloc[i]['Subtype'] == 'Control':\n",
    "        # -1 for no cluster\n",
    "        clusters.append(\"no cluster\")\n",
    "    else:\n",
    "        # find the cluster classification for this cell\n",
    "        found_cluster = find_cell_cluster(adata.obs.iloc[i], cluster_4)\n",
    "        if found_cluster == None: # not a seed cell, no cluster\n",
    "            clusters.append(\"no cluster\")\n",
    "        else:\n",
    "            clusters.append(\"cluster \" + str(found_cluster + 1))    \n",
    "    if i % 100000 == 0:\n",
    "        # approx 500000 in this dataset\n",
    "        print(\"About \" + str(count / 5 * 100) + \"%% done.\")\n",
    "        count += 1\n",
    "    \n",
    "adata.obs['cluster'] = clusters\n",
    "cluster_cmap={'cluster 1': '#45ACEA', 'cluster 2': '#D127A1', 'cluster 3': '#00CC9B', 'cluster 4': '#FFC134', 'no cluster': '#B4C0D2'}\n",
    "# for tma in tma_images:\n",
    "\n",
    "image = \"formatted_S15ROI41\"\n",
    "title = image.split(\"_\")[-1]\n",
    "fn = title + \".png\"\n",
    "save_dir = \"Multiplex_IHC_studies/Summer_Interns/2024/spatial/JT_spatial_output/scatterplots\"\n",
    "spatial_scatterPlot(adata, colorBy=['cluster'], subset=[image], figsize=(5,5), s=0.7, fontsize=5, title=title, customColors=cluster_cmap, fileName=fn, saveDir=save_dir)\n",
    "# note: it is only plotting seed cells as cluster classified since those were the only ones that we were keeping track of "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:scimap] *",
   "language": "python",
   "name": "conda-env-scimap-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
